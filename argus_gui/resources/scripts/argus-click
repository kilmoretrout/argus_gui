#!/usr/bin/env python
# -*- coding: utf-8 -*-

from __future__ import absolute_import
import yaml
# from six.moves import map
import os
import sys

from pyglet.window import key, mouse
from pyglet.graphics import *
#from pygarrayimage.arrayimage import ArrayInterfaceImage

from argus_gui import ArgusColors, FrameFinder, ClickerProject
from argus_gui.tools import *
from argus_gui.arrayImage import ArrayInterfaceImage

import itertools
import math
import pandas
import argus.ocam
import matplotlib.pyplot as plt
from scipy.sparse import csc_matrix, lil_matrix
import time
import numpy as np
import copy

from PySide6 import QtWidgets, QtCore

colors = ArgusColors()
colors = colors.getPygletColors()

colors = [(u[0], u[1], u[2], 180) for u in colors]

# Define the colors we will use in RGBA format
CAROLINA_BLUE = (153, 186, 221, 255)  # Go Tar Heels!
MARKER_COLOR = (255, 105, 180, 200)


class GoToPopupWindow(QtWidgets.QDialog):
    """Popup window for skipping to specified frame
    """
    def __init__(self, number_of_frames, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Enter frame number")
        layout = QtWidgets.QVBoxLayout(self)
        self.go_to_frame = QtWidgets.QSpinBox()
        self.go_to_frame.setValue(current_frame)
        layout.addWidget(self.go_to_frame)
        self.label = QtWidgets.QLabel(f'out of {number_of_frames}')
        layout.addWidget(self.label)
        button = QtWidgets.QPushButton("Ok")
        button.clicked.connect(self.accept)
        layout.addWidget(button)
    
    def showEvent(self, event):
        super().showEvent(event)
        self.go_to_frame.setFocus()
        self.go_to_frame.selectAll()

class YesNoPopup(QtWidgets.QWidget):
    def __init__(self, question):
        super().__init__()

        reply = QMessageBox.question(self, "Question", question, QMessageBox.Yes | QMessageBox.No)

        if reply == QMessageBox.Yes:
            self.reply = "Yes"
        else:
            self.reply = "No"

class OpenFilePopup(QtWidgets.QWidget):
    def __init__(self, win_title, init, filt):
        super().__init__()
        self.filename, _ = QtWidgets.QFileDialog.getOpenFileName(self, caption = win_title, dir = init, filter = filt)

class SaveFilePopup(QtWidgets.QWidget):
    def __init__(self, win_title, init, filt):
        super().__init__()
        self.filename, _ = QtWidgets.QFileDialog.getSaveFileName(self, caption=win_title, dir = init, filter = filt)

class SleepyWindow(object):
    """# Ghostly, or sleepy window, helps Mac OS oddities
    """

    def __init__(self, master):
        top = self.top = Toplevel(master)
        top.withdraw()

    def cleanup(self):
        self.top.destroy()

def load_camera(filename):
    global camera_profile
    global camera_filename
    if filename:
        camera_profile = np.loadtxt(filename)
        # Pinhole distortion
        if camera_profile.shape[1] == 12:
            # Format the camera profile to how SBA expects it
            # i.e. take out camera number column, image width and height, then add in skew.
            camera_profile = np.delete(camera_profile, [0, 2, 3, 6], axis=1)

        # CMei's omnidirectional distortion model
        # Citation: http://www.robots.ox.ac.uk/~cmei/articles/single_viewpoint_calib_mei_07.pdf
        elif camera_profile.shape[1] == 13:
            new_list = []
            camera_number_checker = 1
            for profile in camera_profile:
                try:
                    if profile[0] != camera_number_checker:
                        QtWidgets.QMessageBox.warning(None,
                            "Error",
                            "Camera indexes are either not correctly formatted or non-existence"
                        )
                    # Remove the camera index
                    profile = np.delete(profile, [0])

                    # build the list of CMeiUndistorter objects (can't replace them in place as the original
                    # array is numpy and won't accept varying type
                    new_list.append(argus.ocam.CMeiUndistorter(argus.ocam.ocam_model.from_array(profile)))
                    camera_number_checker += 1
                # TODO: Better Error Handling
                except Exception as e:
                    print(e)
                    QtWidgets.QMessageBox.warning(None,
                        "Error",
                        "Could not load Camera profile!"
                    )
                    return
            camera_profile = new_list


        # Scaramuzza's omnidirectional distortion model
        # Citation: http://rpg.ifi.uzh.ch/docs/omnidirectional_camera.pdf
        else:
            new_list = []
            camera_number_checker = 1 
            for profile in camera_profile:
                try:
                    if profile[0] != camera_number_checker:
                        QtWidgets.QMessageBox.warning(None,
                            "Error",
                            "Camera indexes are either not correctly formatted or non-existent"
                        )
                        return
                    # Remove the camera index
                    profile = np.delete(profile, [0])

                    # build the list of PointUndistorter objects (can't replace them in place as the original
                    # array is numpy and won't accept varying type
                    new_list.append(argus.ocam.PointUndistorter(argus.ocam.ocam_model.from_array(profile)))
                    camera_number_checker += 1
                # TODO: Better Error Handling
                except Exception as e:
                    print(e)
                    QtWidgets.QMessageBox.warning(None,
                        "Error",
                        "Could not load Camera profile!"
                    )
                    return
            camera_profile = new_list
        camera_filename = filename

class OptionsPopupWindow(QtWidgets.QDialog):
    """# popup window for the options dialog
    """

    def __init__(self, sync, auto, track_list, track, disp, bstrap, o_sparse, rgb, parent=None):

        super().__init__(parent)
        self.setWindowTitle("Options")

        self.o_sparse = o_sparse
        self.rgb = rgb
        self.track_list = track_list

        self.cam_entry = QtWidgets.QLineEdit()
        self.lc = QtWidgets.QPushButton('Load camera profile')
        self.lc.clicked.connect(self.load_camera)
        
        self.dlt = QtWidgets.QLineEdit()
        self.ld = QtWidgets.QPushButton('Load DLT coefficients')
        self.ld.clicked.connect(self.load_DLT)

        self.tracks = QtWidgets.QComboBox()
        self.tracks.addItems(track_list)
        self.track = track
        self.tracks.setCurrentText(self.track)

        self.add_button = QtWidgets.QPushButton("Add a new track")
        self.add_button.clicked.connect(self.newTrack)

        self.disp = QtWidgets.QCheckBox("Display all tracks")
        self.disp.setChecked(disp)

        self.sync = QtWidgets.QCheckBox("Keep all videos in same frame")
        self.sync.setChecked(sync)

        self.auto = QtWidgets.QCheckBox("Automatically advance frames")
        self.auto.setChecked(auto)

        self.bstrap = QtWidgets.QCheckBox("Save 95% CIs, spline filtering weights,\nand error tolerance")
        self.bstrap.setChecked(bstrap)

        self.formatlabel = QtWidgets.QLabel("Save format: ")
        self.formatbox = QtWidgets.QComboBox()
        self.formatbox.addItems(["Dense .csv", "Sparse .tsv"])
        self.formatbox.currentIndexChanged.connect(self.sparse_toggle)
        if self.o_sparse:
            self.formatbox.setCurrentText("Sparse .tsv")
        else:
            self.formatbox.setCurrentText("Dense .csv")

        self.colorlabel = QtWidgets.QLabel("Display: ")
        self.colorbox = QtWidgets.QComboBox()
        self.colorbox.addItems(['RGB color', 'grayscale'])
        self.colorbox.currentIndexChanged.connect(self.color_toggle)
        if self.rgb:
            self.colorbox.setCurrentText('RGB color')
        else:
            self.colorbox.setCurrentText('grayscale')

        self.savelabel = QtWidgets.QLabel("Save location/tag: ")
        self.fnam = QtWidgets.QLineEdit()
        self.save_button = QtWidgets.QPushButton('Specify')
        self.save_button.clicked.connect(self.save_as)

        self.okbutton = QtWidgets.QPushButton("Ok")
        self.okbutton.clicked.connect(self.accept)
        
        # set values to globals if they are already set
        self.cam_entry.setText(camera_filename)
        self.dlt.setText(dlt_filename)
        self.fnam.setText(global_filename)
        
        # GUI structure
        genlabel = QtWidgets.QLabel("General Settings")
        displabel = QtWidgets.QLabel("Display options")
        outlabel = QtWidgets.QLabel("Save Settings")
        divider1 = QtWidgets.QFrame()
        divider1.setFrameShape(QtWidgets.QFrame.HLine)
        divider1.setFrameShadow(QtWidgets.QFrame.Sunken)
        divider2 = QtWidgets.QFrame()
        divider2.setFrameShape(QtWidgets.QFrame.HLine)
        divider2.setFrameShadow(QtWidgets.QFrame.Sunken)        

        layout = QtWidgets.QGridLayout(self)
        layout.addWidget(genlabel, 0, 0)
        layout.addWidget(self.cam_entry, 1, 0, 1, 2)
        layout.addWidget(self.lc, 1, 2)
        layout.addWidget(self.dlt, 2, 0, 1, 2)
        layout.addWidget(self.ld, 2, 2)
        layout.addWidget(self.tracks, 3, 0)
        layout.addWidget(self.add_button, 3, 1)

        layout.addWidget(divider1, 4, 0, 1, 3)
        layout.addWidget(displabel, 5, 0, 1, 3)
        layout.addWidget(self.disp, 6, 0)
        layout.addWidget(self.auto, 7, 0)
        layout.addWidget(self.sync, 8, 0)
        layout.addWidget(self.colorlabel, 9, 0)
        layout.addWidget(self.colorbox, 9, 0, QtCore.Qt.AlignRight)
        
        layout.addWidget(divider2, 10, 0, 1, 3)
        layout.addWidget(outlabel, 11, 0, 1, 3)
        layout.addWidget(self.bstrap, 12, 0)
        layout.addWidget(self.formatlabel, 13, 0)
        layout.addWidget(self.formatbox, 13, 0, QtCore.Qt.AlignRight)
        layout.addWidget(self.savelabel, 14, 0)
        layout.addWidget(self.fnam, 15, 0, 1, 2)
        layout.addWidget(self.save_button, 15, 2)
        layout.addWidget(self.okbutton, 16, 2)

        # self.track_list = track_list
        # self.dlts = list()

    # close with Return key
    def keyPressEvent(self, event):
        if event.key() == QtCore.Qt.Key_Return:
            self.accept()

    # popup window for inputting track name
    def newTrack(self):
        track_name_window = newTrackPopup(self)
        if track_name_window.exec_() == QtWidgets.QDialog.Accepted:
            new_name = track_name_window.line_edit.text()

        # check to make sure the track name is not empty and does not already exist
        if new_name != '' and new_name not in self.track_list:
            self.track_list.append(new_name)
            self.tracks.addItem(new_name)
            self.tracks.setCurrentText(new_name)

        else:
            QtWidgets.QMessageBox.warning(None,
                "Error",
                "Track names must be unique and non-empty"
            )

    def load_camera(self):
        filename, _ = QtWidgets.QFileDialog.getOpenFileName(self, "Choose camera profile", filter="Text files (*.txt)")
        try:
            if filename:
                load_camera(filename)
                self.cam_entry.setText(filename)
        except:
            QtWidgets.QMessageBox.warning(None,
                "Error",
                "Could not load Camera profile!"
            )

    def load_DLT(self):
        global DLTCoefficients
        global dlt_filename
        filename, _ = QtWidgets.QFileDialog.getOpenFileName(self, "Choose DLT coefficients file", filter="CSV files (*.csv)")

        if filename:
            try:
                DLTCoefficients = np.loadtxt(filename, delimiter=',')
                DLTCoefficients = DLTCoefficients.T
                self.dlt.setText(filename)
                dlt_filename = filename
            # TODO: Better Exception Handling
            except:
                QtWidgets.QMessageBox.warning(None,
                    "Error",
                    "Could not load DLT coefficients!"
                )
            
    def sparse_toggle(self):
        if self.formatbox.currentText() == "Sparse .tsv":
            self.o_sparse = True
        elif self.formatbox.currentText() == "Dense .csv":
            self.o_sparse = False

    def color_toggle(self):
        if self.colorbox.currentText() == "RGB color":
            self.rgb == True
        elif self.colorbox.currentText() == "grayscale":
            self.rgb == False

    def save_as(self):
        global global_filename
        filename, _ = QtWidgets.QFileDialog.getSaveFileName(self, "Select location and enter file name prefix")
        if filename != '':
            self.fnam.setText(filename)
            global_filename = filename

class newTrackPopup(QtWidgets.QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Name the new track")
        layout = QtWidgets.QVBoxLayout(self)
        self.line_edit = QtWidgets.QLineEdit()
        layout.addWidget(self.line_edit)
        button = QtWidgets.QPushButton("Ok")
        button.clicked.connect(self.accept)
        layout.addWidget(button)

def draw_circle(coordinates, radius, color=(255, 255, 255), batch=None, strip=False):
    """Modified versions of code in pgedraw. returns vertices rather than having them as an attribute of a class
    :param coordinates: The coordinates of the center of the circle
    :param radius: The desired radius of the circle
    :param color: The color of the circle
    :param batch: pyglt batch for faster drawing
    :param strip: // TODO: Better documentation
    :return:
    """

    (x, y) = coordinates
    radius = radius

    vertices = [float(x), float(y)]

    for deg in range(0, 361, 2):
        angle = (deg * math.pi) / 180
        vertices.extend((x + math.sin(angle) * radius, y + math.cos(angle) * radius))

    pn = int(len(vertices) / 2)
    list_of_vertices = batch.add(pn, GL_POINTS, None,
                                 ('v2f/static', vertices),
                                 ('c4B/static', color * pn)
                                 )

    return list_of_vertices


def draw_line(vertices, color=(255, 255, 255), batch=None):
    mode = GL_LINES
    color = color

    list_of_vertices = batch.add(2, mode, None,
                                 ('v2f', tuple(itertools.chain(*vertices))),
                                 ('c4B', color * 2)
                                 )
    return list_of_vertices


# global variables for options and current track
# all windows pay attention to and modify these
# set to defaults
track_list_global = ['Track 1']
current_track_global = 'Track 1'
auto_advance = True
sync = False
displaying_all_tracks = False
current_frame = 1
common = dict()
load_data_global = None
no_cameras_global = 0
DLTCoefficients = None
camera_profile = None
bstrap = False
busy = False
outputSparse = False
global_filename = ''
rgb = True
vx = 15
vy = 15
# vf = 30

dlt_filename = ''
camera_filename = ''

# Zooming constants
ZOOM_IN_FACTOR = 1.2
ZOOM_OUT_FACTOR = 1 / ZOOM_IN_FACTOR


# called once to load the CSV into a numpy array a populate the track list, expects a header
def load_csv(csv):
    global load_data_global
    global no_cameras_global
    global track_list_global
    global current_track_global

    # sys.stdout.flush()

    try:
        track_csv = open(csv)
        header = track_csv.readline()
        new_tracks = []
        header = header.split(',')
        for st in header:
            if st.rsplit('_', 3)[0] not in new_tracks:
                new_tracks.append(st.rsplit('_', 3)[0])

        track_csv.close()

        track_list_global = new_tracks
        current_track_global = track_list_global[0]

        # sys.stdout.flush()
        load_data_global = np.array(pandas.read_csv(csv, index_col=False).values, dtype=np.float16)
        load_data_global[np.isnan(load_data_global)] = 0
        load_data_global = csc_matrix(load_data_global)
        no_cameras_global = len([u for u in pyglet.app.windows if type(u) != GhostWindow])

    # TODO: Better Exception Handling
    except:
        QtWidgets.QMessageBox.warning(None,
            "Error",
            "Could not load CSV! Make sure it is formatted according to the documentation."
        )
    # sys.stdout.flush()


# for sparse data files as TSVs
def load_tsv(tsv):
    global load_data_global
    global no_cameras_global
    global track_list_global
    global current_track_global

    try:
        # load the file, expects a header
        csv_data = pandas.read_csv(tsv, index_col=False, sep='\t', skiprows=1)
        # read into numpy array
        load_data_global = np.zeros((int(list(csv_data.keys())[0]), int(list(csv_data.keys())[1])), dtype=np.float16)
        csv_data = csv_data.values
        for k in range(len(csv_data)):
            load_data_global[int(csv_data[k, 0]) - 1, int(csv_data[k, 1]) - 1] = csv_data[k, 2]

        # convert to compressed sparse matrix form
        load_data_global = csc_matrix(load_data_global)

        no_cameras_global = len([u for u in pyglet.app.windows if type(u) != GhostWindow])

        track_list_global = list()
        for k in range(int(load_data_global.shape[1] / (2 * no_cameras_global))):
            track_list_global.append('Track ' + str(k + 1))

        current_track_global = track_list_global[0]
    except:
        QtWidgets.QMessageBox.warning(None,
            "Error",
            "Could not load TSV! Make sure it is formatted according to the documentation."
        )


# TODO: Implement abstract classes
# main class which displays the movie's individual frames and allows users to mark points
class ClickerWindow(pyglet.window.Window):
    def __init__(self, movie, offsets, actual_camera_number, end, factor, last=False):
        self.actual_camera_number = actual_camera_number
        self.original_index = actual_camera_number - 1

        # Function for converting openCV images to pyglt compatible frames
        self.frameFinder = FrameFinder(movie, factor=factor, offset=offsets[self.original_index], rgb=rgb)

        super(ClickerWindow, self).__init__(width=int(float(self.frameFinder.ow) / factor),
                                            height=int(float(self.frameFinder.oh) / factor), visible=True,
                                            resizable=True, vsync=True)

        self.movie = movie
        self.offsets = offsets

        self.end = end
        self.points = {}
        self.current_point_index = 1
        self.displayingFrameNumber = True
        self.displayingDLTLines = False
        self.set_caption('{0} - Frame {1} - Track: {2}'.format(movie.split('/')[-1], 1, current_track_global))
        self.folder = ''
        self.current_marker = None
        self.scale_factor = factor

        # create array to keep track of offset changes
        self.offsets_output = np.zeros(self.end)
        self.offsets_output[:] = np.nan

        if self.actual_camera_number == 1:
            self.base = True
        else:
            self.base = False

        self.trackingColors = list()
        self.previous = list()
        self.autoTracking = False

        # batches for fast drawing
        self.main_batch = pyglet.graphics.Batch()
        self.track_batch = pyglet.graphics.Batch()
        self.background = pyglet.graphics.OrderedGroup(0)
        self.dlt_batch = pyglet.graphics.Batch()
        # img is array format from cv2
        img = self.frameFinder.getFrame(1)
        if img is not None:
            self.img = pyglet.sprite.Sprite(ArrayInterfaceImage(img).get_texture())
            self.img.x = 0
            self.img.y = 0
            self.img.scale = float(self.scale_factor)
        else:
            self.img = None

        # current mouse coordinate for getting a zoomed view finder
        self.x = 0
        self.y = 0
        self.view = None

        # modifiable boolean for showing the zoomed view finder
        self.show_view = True

        # dictionaries for storing OpenGL vertices and deleting later if needed
        self.drawn_points = {}
        self.drawn_lines = {}

        # Initialize camera values
        self.left = 0
        self.right = self.frameFinder.ow
        self.bottom = 0
        self.top = self.frameFinder.oh
        self.zoom_level = 1
        self.zoomed_width = self.frameFinder.ow
        self.zoomed_height = self.frameFinder.oh

        self.update_tracks()

        # It's the strangest thing... (I'm assuming that this is the only way it will work on Darwin systems)
        # if last and sys.platform == 'darwin':
        #     root = Tk()
        #     root.withdraw()
        #     root.after(100, root.destroy)
        #     w = SleepyWindow(root)
        #     root.wait_window(w.top)

        self.init_gl()

        self.changed = False

        self.vf = int(np.round(self.frameFinder.oh / (vx * 3.)))

    # only called upon loading a CSV. Pretty slow to define tons of vertices.
    def draw_tracks(self):
        self.update_tracks()
        track = current_track_global

        positions = self.points[track].A
        non_zeros = list(set(self.points[track].nonzero()[0]))

        radius = 2

        if self.current_point_index - 1 in non_zeros:
            self.current_marker = draw_circle(
                tuple(positions[self.current_point_index - 1]),
                4,
                MARKER_COLOR,
                self.track_batch
            )

        for non_zero_value in non_zeros:
            self.drawn_points[track][non_zero_value] = draw_circle(
                tuple(positions[non_zero_value]),
                radius,
                colors[track_list_global.index(track) % len(colors)], self.track_batch
            )

        for non_zero_value in non_zeros:
            if non_zero_value + 1 in non_zeros:
                t = tuple([positions[non_zero_value], positions[non_zero_value + 1]])
                self.drawn_lines[track][non_zero_value] = draw_line(
                    t,
                    colors[track_list_global.index(track) % len(colors)],
                    self.track_batch
                )

        if displaying_all_tracks:
            for track in self.points.keys():
                if track != current_track_global:
                    positions = self.points[track].A
                    non_zeros = list(set(self.points[track].nonzero()[0]))
                    for non_zero_value in non_zeros:
                        if non_zero_value + 1 in non_zeros:
                            t = tuple([positions[non_zero_value], positions[non_zero_value + 1]])
                            self.drawn_lines[track][non_zero_value] = draw_line(t,
                                                                                colors[track_list_global.index(
                                                                                    track) % len(colors)],
                                                                                self.track_batch)

    # called when the user decides to display all the tracks
    def draw_all_tracks(self):
        self.update_tracks()
        for track in self.points.keys():
            positions = self.points[track].A
            nz = list(set(self.points[track].nonzero()[0]))

            if track != current_track_global:
                for k in nz:
                    if k + 1 in nz:
                        t = tuple([positions[k], positions[k + 1]])
                        self.drawn_lines[track][k] = draw_line(t, colors[track_list_global.index(track) % len(colors)],
                                                               self.track_batch)

    # called when the user decides not to display all the tracks
    def delete_all_tracks(self):
        for track in self.points.keys():
            if track != current_track_global:
                for k in range(len(self.drawn_points[track])):
                    if self.drawn_points[track][k] is not None:
                        self.drawn_points[track][k].delete()
                        self.drawn_points[track][k] = None

                for k in range(len(self.drawn_lines[track])):
                    if self.drawn_lines[track][k] is not None:
                        self.drawn_lines[track][k].delete()
                        self.drawn_lines[track][k] = None

    # called when the user changes tracks
    def change_track(self, old_track):
        radius = 2

        for k in range(len(self.drawn_points[old_track])):
            if self.drawn_points[old_track][k] is not None:
                self.drawn_points[old_track][k].delete()
                self.drawn_points[old_track][k] = None

        if not displaying_all_tracks:
            for k in range(len(self.drawn_lines[old_track])):
                if self.drawn_lines[old_track][k] is not None:
                    self.drawn_lines[old_track][k].delete()
                    self.drawn_lines[old_track][k] = None

        positions = self.points[current_track_global].A
        nz = list(set(self.points[current_track_global].nonzero()[0]))

        if self.current_marker is not None:
            self.current_marker.delete()
            self.current_marker = None

        if self.current_point_index - 1 in nz:
            self.current_marker = draw_circle(tuple(positions[self.current_point_index - 1]), 4, MARKER_COLOR,
                                              self.track_batch)

        for k in nz:
            self.drawn_points[current_track_global][k] = draw_circle(tuple(positions[k]), radius, colors[
                track_list_global.index(current_track_global) % 4], self.track_batch)

        if not displaying_all_tracks:
            for k in nz:
                if k + 1 in nz:
                    t = tuple([positions[k], positions[k + 1]])
                    self.drawn_lines[current_track_global][k] = draw_line(t, colors[
                        track_list_global.index(current_track_global) % 4], self.track_batch)

    def on_mouse_drag(self, x, y, dx, dy, buttons, modifiers):
        """Allows the user to drag around the current frame
        It's worth noting that in the BaseWindow class (a distant parent of this class) the function
        on_mouse_drag takes : x, y, dx, dy, buttons, modifiers as parameters with x oddly occupying the spot of
        self. However, in practice, all 6 parameters are passed, meaning that function signature simply can't be
        reimplemented.

        :param x: The current X value
        :param y: The current Y value
        :param dx: The distance the mouse was moved horizontally
        :param dy: The distance the mouse was moved vertically
        :param buttons: The buttons used in the drag
        :param modifiers: // TODO Better doc.
        :return: None
        """
        # Move camera
        if modifiers & key.MOD_SHIFT:
            left = self.left - dx * self.zoom_level
            right = self.right - dx * self.zoom_level
            bottom = self.bottom - dy * self.zoom_level
            top = self.top - dy * self.zoom_level

            if left >= 0 and bottom >= 0 and right <= self.frameFinder.ow and top <= self.frameFinder.oh:
                self.left, self.right, self.bottom, self.top = left, right, bottom, top
                self.frameFinder.update(self.left, self.bottom, self.right - self.left, self.top - self.bottom)

    # draw a new point
    def draw_new_point(self, x, y):
        track = current_track_global
        radius = 2

        new_point_index = self.current_point_index - 1
        old_point_index = self.current_point_index - 2

        self.points[current_track_global][new_point_index] = np.array([x, y])
        self.offsets_output[new_point_index] = self.offsets[self.original_index]

        # Get the numpy array from the sparse csc_matrix representing the coordinate plane
        # with the bottom left corner as the center
        positions = self.points[track].A

        # Note the extra [0] at the end is because numpy returns ([], ) when nonzero is called
        non_zero_points = set(self.points[track].nonzero()[0])

        # If a point already exists in the new slot
        if self.drawn_points[track][new_point_index] is not None:
            self.drawn_points[track][new_point_index].delete()

        self.drawn_points[track][new_point_index] = draw_circle(
            tuple(positions[new_point_index]),
            radius,
            colors[track_list_global.index(track) % len(colors)],
            self.track_batch
        )

        if new_point_index >= 0:
            # Draws a line from the current point to the previous point
            if old_point_index in non_zero_points:
                point_list = (positions[old_point_index], positions[new_point_index])
                if self.drawn_lines[track][old_point_index] is not None:
                    self.drawn_lines[track][old_point_index].delete()
                    self.drawn_lines[track][old_point_index] = draw_line(point_list,
                                                                         colors[
                                                                             track_list_global.index(track) % len(
                                                                                 colors)
                                                                             ],
                                                                         self.track_batch)
                else:
                    self.drawn_lines[track][old_point_index] = draw_line(point_list,
                                                                         colors[
                                                                             track_list_global.index(track) % len(
                                                                                 colors)
                                                                             ],
                                                                         self.track_batch)

            # Draws a line to points ahead of the current one
            if self.current_point_index in non_zero_points and positions[self.current_point_index][0] != 0:
                point_list = (positions[new_point_index], positions[self.current_point_index])
                if self.drawn_lines[track][new_point_index] is not None:
                    self.drawn_lines[track][new_point_index].delete()
                self.drawn_lines[track][new_point_index] = draw_line(point_list, colors[
                    track_list_global.index(track) % len(colors)], self.track_batch)

        # Reset the current marker
        if self.current_marker is not None:
            self.current_marker.delete()
            self.current_marker = None

        # TODO: Further testing required to see how necessary this is
        # Finally, draw a circle at the new point
        if new_point_index in non_zero_points:
            self.current_marker = draw_circle(
                tuple(positions[new_point_index]),
                radius=4,
                color=MARKER_COLOR,
                batch=self.track_batch
            )

    def change_marker(self):
        self.update_tracks()
        track = current_track_global

        positions = self.points[track].A
        non_zero_points = list(set(self.points[track].nonzero()[0]))

        if self.current_marker is not None:
            self.current_marker.delete()
            self.current_marker = None

        if self.current_point_index - 1 in non_zero_points:
            self.current_marker = draw_circle(tuple(positions[self.current_point_index - 1]), 4, MARKER_COLOR,
                                              self.track_batch)

    # delete a point
    def delete_point(self):
        # if self.current_point_index == 1: return
        #
        # self.current_point_index = 0 if self.current_point_index == 1 else self.current_point_index - 1

        track = current_track_global

        last_added_index = self.current_point_index - 1
        second_most_recent_index = self.current_point_index - 2

        # Reset the current marker
        if self.current_marker is not None:
            self.current_marker.delete()
            self.current_marker = None

        if self.drawn_points[track][last_added_index] is not None:
            self.drawn_points[track][last_added_index].delete()
            self.drawn_points[track][last_added_index] = None
        if self.drawn_lines[track][second_most_recent_index] is not None:
            self.drawn_lines[track][second_most_recent_index].delete()
            self.drawn_lines[track][second_most_recent_index] = None
        if self.drawn_lines[track][last_added_index] is not None:
            self.drawn_lines[track][last_added_index].delete()
            self.drawn_lines[track][last_added_index] = None

    # doesn't really get a bezier curve, just draws lines in between 70 points on the distorted epipolar line
    def get_bezier_curve(self, m, b, prof):
        pts = list()
        for k in range(-10, 60):
            pts.append(np.asarray([self.frameFinder.ow * k / 49., m * (self.frameFinder.ow * k / 49.) + b]))

        ret = redistort_pts(np.asarray(pts), prof)

        ret = np.reshape(ret, (len(pts), 2))
        for k in range(len(ret)):
            ret[k] = ret[k]
        return list(ret)

    # fills the batch for epipolar lines, drawn in Carolina Blue. Go tar heels!
    def make_dlt_batch(self, points):
        for k in range(len(points) - 1):
            t = tuple([points[k], points[k + 1]])
            draw_line(t, CAROLINA_BLUE, self.dlt_batch)

    # Zooms in using OpenGL.  Has bounds so that none of the screen ever has blank space
    def on_mouse_scroll(self, x, y, dx, dy):
        # Get scale factor
        f = ZOOM_IN_FACTOR if dy > 0 else ZOOM_OUT_FACTOR if dy < 0 else 1
        # If zoom_level is in the proper range
        if .05 < self.zoom_level * f < 5:

            zoom_level = f * self.zoom_level

            mouse_x = float(x) / self.width
            mouse_y = float(y) / self.height

            mouse_x_in_world = self.left + mouse_x * self.zoomed_width
            mouse_y_in_world = self.bottom + mouse_y * self.zoomed_height

            zoomed_width = f * self.zoomed_width
            zoomed_height = f * self.zoomed_height

            left = mouse_x_in_world - mouse_x * zoomed_width
            right = mouse_x_in_world + (1 - mouse_x) * zoomed_width
            bottom = mouse_y_in_world - mouse_y * zoomed_height
            top = mouse_y_in_world + (1 - mouse_y) * zoomed_height

            # Check bounds 
            if left >= 0 and bottom >= 0 and right <= self.frameFinder.ow \
                    and top <= self.frameFinder.oh and zoomed_width <= self.frameFinder.ow \
                    and zoomed_height <= self.frameFinder.oh:
                self.left, self.right, self.bottom, self.top, self.zoomed_width, self.zoomed_height = left, right, bottom, top, zoomed_width, zoomed_height
                self.zoom_level = zoom_level
                self.frameFinder.update(self.left, self.bottom, self.right - self.left, self.top - self.bottom)

    # uses Hedrick's function to get a slope and intercept for the Epipolar lines
    def get_epipolar_lines(self):
        global DLTCoefficients
        global dlt_filename
        global camera_profile
        global camera_filename

        self.update_tracks()
        coordinates = []
        tmp = []
        dlt_coeff_2 = DLTCoefficients[self.original_index]

        for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
            if self is not window:
                try:
                    coordinates.append([window.actual_camera_number,
                                        window.points[current_track_global][self.current_point_index - 1].toarray()[0]])
                except Exception as e:
                    print(e)
        coordinates = sorted(coordinates)
        for coordinate in coordinates:
            if True not in (coordinate[1] == 0):
                dlc_coeff_1 = DLTCoefficients[coordinate[0] - 1]
                x_cord = coordinate[1][0]
                y_cord = coordinate[1][1]


                # The coordinate has the first value of the camera
                # Thus the camera profile is indexing at the literal profile for this camera
                if camera_profile is not None:
                    try:
                        _ = undistort_pts(np.asarray([x_cord, y_cord]), camera_profile[coordinate[0] - 1])[0]
                        x_cord = _[0]
                        y_cord = _[1]
                    except np.linalg.LinAlgError as e:
                        QtWidgets.QMessageBox.warning(None,
                            "Error",
                            f"Numpy complained with the following message: \n{e}\n"
                            "This typically indicates a malformed camera profile or incorrect DLT Coefficients\n"
                            "To prevent future dialogs from appearing, DLT Coefficients are going to be set to null. "
                            "If you would like to re-enable this feature, check your profile and coefficents again and reload "
                            "them."
                        )
                        DLTCoefficients = None
                        dlt_filename = ""
                        camera_profile = None
                        camera_filename = ""

                slope, intercept = getDLTLine(x_cord, y_cord, dlc_coeff_1, dlt_coeff_2)

                if camera_profile is None:
                    tmp.append(np.asarray([0, intercept]))
                    tmp.append(np.asarray([self.frameFinder.ow, slope * self.frameFinder.ow + intercept]))
                else:
                    tmp = self.get_bezier_curve(slope, intercept, camera_profile[coordinate[0] - 1])
                self.make_dlt_batch(tmp)

    # makes sure all the dictionaries have the proper keys
    def update_tracks(self):
        for track in track_list_global:
            try:
                self.points[track]
            except KeyError:
                self.points[track] = csc_matrix((self.end, 2))

            try:
                # Checks if the track key exists
                self.drawn_points[track]
                self.drawn_lines[track]
            except KeyError:
                self.drawn_points[track] = list()
                self.drawn_lines[track] = list()
                for k in range(self.points[track].shape[0]):
                    self.drawn_points[track].append(None)
                for k in range(self.points[track].shape[0] - 1):
                    self.drawn_lines[track].append(None)

    # called by each window upon saving.
    # Fills a common dictionary with its tracks which is then written to a CSV using pandas.
    def fill_common_dictionary(self):
        global common

        uvs = dict()
        for track in self.points.keys():
            uvs[track] = copy.copy(self.points[track].toarray())
            uvs[track][uvs[track] == 0] = np.nan
            common[track + '_cam_' + str(self.actual_camera_number) + '_x'] = uvs[track][:, 0]
            common[track + '_cam_' + str(self.actual_camera_number) + '_y'] = uvs[track][:, 1]

    # called for each window after the common dictionary is filled.
    # probably a more intuitive way to grab parts rather than indexing them
    def load_points(self):
        global load_data_global
        # for each track, load in your points
        matching = True

        # sys.stdout.flush()
        for track in self.points.keys():
            # sys.stdout.flush()
            current_track_index = track_list_global.index(track)
            self.points[track] = load_data_global[:,
                                 2 * current_track_index * no_cameras_global + 2 * self.original_index:
                                 2 * current_track_index * no_cameras_global + 2 * self.original_index + 2]

            if self.points[track].shape[0] > self.end:
                matching = False
        self.clearBatch()
        # sys.stdout.flush()
        start_time = time.clock()

        self.draw_tracks()

        return matching

    def init_gl(self):
        # Set clear color
        glClearColor(0 / 255, 0 / 255, 0 / 255, 0 / 255)

        # Set antialiasing
        glEnable(GL_LINE_SMOOTH)
        # glEnable( GL_POLYGON_SMOOTH )
        glHint(GL_LINE_SMOOTH_HINT, GL_NICEST)

        # Set alpha blending
        glEnable(GL_BLEND)
        glBlendFunc(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA)

        # Set viewport
        glViewport(0, 0, self.width, self.height)

        # Initialize Projection matrix
        glMatrixMode(GL_PROJECTION)
        glLoadIdentity()

        # Set orthographic projection matrix
        glOrtho(0, self.width, 0, self.height, 1, -1)

        # Initialize Modelview matrix
        glMatrixMode(GL_MODELVIEW)
        glLoadIdentity()

        # Save the default modelview matrix
        glPushMatrix()

    def on_draw(self):
        self.clear()

        glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)

        # Initialize Projection matrix
        glMatrixMode(GL_PROJECTION)
        glLoadIdentity()

        # Initialize Modelview matrix
        glMatrixMode(GL_MODELVIEW)
        glLoadIdentity()

        try:
            while True:
                glPopMatrix()
        except Exception as e:
            pass

        glPushMatrix()

        glOrtho(self.left, self.right, self.bottom, self.top, 1, -1)

        if self.x != 0 and self.y != 0:
            try:
                view = self.frameFinder.getViewFinder(self.current_point_index, self.x, self.y, vx, vy, self.vf,
                                                      self.autoTracking)
                # mark discrete estimate with red cross
                view[int(view.shape[0] / 2), :] = np.array([255., 0., 0.])
                view[:, int(view.shape[1] / 2)] = np.array([255., 0., 0.])
            except:
                view = None
            if view is not None:
                scale = (((self.right - self.left) * (self.top - self.bottom)) / (
                        self.frameFinder.oh * self.frameFinder.ow)) ** 0.5
                self.view = pyglet.sprite.Sprite(ArrayInterfaceImage(view).get_texture(),
                                                 x=self.right - np.floor(vx * self.vf * scale), y=self.bottom)
                self.view.scale = scale

        if self.current_point_index != current_frame and sync:
            self.current_point_index = current_frame
        # If there exists a frame relative to the first camera, display it. else you get a black screen

        if self.changed:
            im = self.frameFinder.getFrame(self.current_point_index)
            if im is not None:
                if self.img is not None:
                    self.img.image = ArrayInterfaceImage(im)
                else:
                    self.img = pyglet.sprite.Sprite(ArrayInterfaceImage(im))
                    self.img.scale = float(self.scale_factor)
            else:
                self.img = None
        # self.img.blit(0,0, width = self.frameFinder.ow, height = self.frameFinder.oh)

        if self.img is not None:
            self.img.draw()

        if self.view is not None and self.show_view:
            self.view.draw()
        # if DLT coefficients are present, draw epipolar lines in Carolina Blue
        if DLTCoefficients is not None:
            self.dlt_batch = pyglet.graphics.Batch()
            self.get_epipolar_lines()
            self.dlt_batch.draw()
        if not busy:
            # if not self.base:
            self.set_caption(
                '{0} - Frame {1}, Offset: {2} - Track: {3}'.format(self.movie.split('/')[-1], self.current_point_index,
                                                                   self.frameFinder.offset, current_track_global))
        else:
            self.set_caption('{0} - Working...'.format(self.movie.split('/')[-1]))

        self.track_batch.draw()

    def tick(self):
        global sync

        if sync:
            sync = False
        if self.autoTracking:
            uv = self.points[current_track_global][self.current_point_index - 2].toarray()[0]
            pts = self.points[current_track_global].A

            if self.frameFinder.kf is None:
                nz = sorted(list(set(self.points[current_track_global].nonzero()[0])))
                ind = [self.current_point_index - 2]
                for k in range(20):
                    if self.current_point_index - (3 + k) in nz:
                        ind = [self.current_point_index - (3 + k)] + ind
                    else:
                        break
                if len(ind) >= 2:
                    self.frameFinder.makeKalman(pts[ind])
            if uv[0] != 0:
                try:
                    pos = self.frameFinder.CrossTrack(uv[0] - vx, (self.frameFinder.oh - uv[1]) - vy, 2 * vx, 2 * vy)
                    if self.frameFinder.kf is not None:
                        self.frameFinder.update_kalman(pos)
                except Exception as e:
                    print(e)
                    self.autoTracking = False
                    pyglet.clock.unschedule(up)
                    return
                if not True in np.isnan(pos):
                    self.draw_new_point(pos[0], pos[1])

                self.changed = True
                self.current_point_index += 1
                if sync:
                    self.update_all_windows()
                    # self.updateSelf()
            else:
                self.autoTracking = False
                pyglet.clock.unschedule(up)
                return

    # called to make sure everybody gets the changes made by one window
    def update_all_windows(self):
        for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
            if self is not window:
                window.switch_to()
                window.update_tracks()
                window.dispatch_events()
                window.dispatch_event('on_draw')
                window.change_marker()
                window.flip()

    def dense_to_sparse(self, arr):
        # create a sparse data file with rows and columns indexed by the natural numbers
        # as per MATLAB etiquette
        row = list()
        col = list()
        val = list()
        for k in range(len(arr)):
            for j in range(arr.shape[1]):
                if not np.isnan(arr[k, j]):
                    row.append(k + 1)
                    col.append(j + 1)
                    val.append(arr[k, j])

        out = np.zeros((len(row) + 1, 3))
        out[1:, 0] = np.array(row)
        out[1:, 1] = np.array(col)
        out[1:, 2] = np.array(val)
        out[0, 0] = len(arr)
        out[0, 1] = arr.shape[1]
        out[0, 2] = len(row)
        return out

    def save_sparse(self, save_as=True):
        global global_filename

        if save_as or global_filename == '':
            app = QtWidgets.QApplication.instance()
            if app is None:
                app = QtWidgets.QApplication([])
            w = SaveFilePopup("Select location and enter prefix for sparse file", global_filename.split('/')[-1], 'All files (*.*)')
            if w.filename:
                filename = w.filename
        else:
            filename = global_filename

        if filename != '' and type(filename) == str:
            global_filename = filename
            for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
                window.fill_common_dictionary()

            offsets_out = list()

            for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
                offsets_out.append(window.offsets_output)

            offsets_out = np.array(offsets_out).T

            # get the header
            cols = sorted(common.keys())
            # stack all the columns together
            _ = common[cols[0]]
            _ = np.reshape(_, (_.shape[0], 1))
            for k in range(1, len(cols)):
                _ = np.hstack((_, np.reshape(common[cols[k]], (_.shape[0], 1))))
            pts = _

            dataf = pandas.DataFrame(self.dense_to_sparse(pts), columns=['Row', 'Column', 'Entry'])
            dataf[['Row', 'Column']] = dataf[['Row', 'Column']].astype(np.uint32)
            dataf.iloc[0].apply(np.uint32)
            if DLTCoefficients is not None and camera_profile is not None:
                # make a data frame for the xyz coordinates for all tracks and all frames
                xyzss = list()
                for j in range(pts.shape[1] // (2 * len(camera_profile))):
                    xyzs = uv_to_xyz(pts[:, j * 2 * len(camera_profile):(j + 1) * 2 * len(camera_profile)],
                                     camera_profile, DLTCoefficients)
                    # cPickle.dump(pts[:,j*2*len(CameraProfile):(j+1)*2*len(CameraProfile)], open('points' + str(j) + '.p', 'wb'))
                    xyzss.append(xyzs)
                xyzss = np.asarray(xyzss)
                _ = xyzss[0]
                for k in range(1, len(xyzss)):
                    _ = np.hstack((_, xyzss[k]))

                dataf1 = pandas.DataFrame(self.dense_to_sparse(_), columns=['Row', 'Column', 'Entry'])
                dataf1[['Row', 'Column']] = dataf1[['Row', 'Column']].astype(np.uint32)
                dataf1.iloc[0].apply(np.uint32)

                # save offsets (always non-sparse)
                datafo = pandas.DataFrame(offsets_out, columns=['camera_{0}'.format(u) for u in range(1, len(
                    [u for u in pyglet.app.windows if type(u) != GhostWindow]) + 1)])
                datafo.to_csv(filename + '-offsets.csv', index=False, na_rep='NaN')

                # get reprojection errors for all 3d points and make a data frame for it
                repoErrs = get_repo_errors(_, pts, camera_profile, DLTCoefficients).T
                dataf2 = pandas.DataFrame(self.dense_to_sparse(repoErrs), columns=['Row', 'Column', 'Entry'])
                dataf2[['Row', 'Column']] = dataf2[['Row', 'Column']].astype(np.uint32)
                dataf2.iloc[0].apply(np.uint32)

                if bstrap:
                    CIs, weights, tols = bootstrapXYZs(pts, repoErrs, camera_profile, DLTCoefficients)
                    upper = _ + CIs
                    lower = _ - CIs

                    _ = np.zeros((upper.shape[0], upper.shape[1] * 2))
                    _[_ == 0] = np.nan
                    for k in range(int(upper.shape[1] / 3)):
                        _[:, 2 * k * 3:2 * (k + 1) * 3] = np.concatenate(
                            (lower[:, k * 3:(k + 1) * 3], upper[:, k * 3:(k + 1) * 3]), axis=1)
                    dataf3 = pandas.DataFrame(self.dense_to_sparse(_), columns=['Row', 'Column', 'Entry'])
                    dataf3[['Row', 'Column']] = dataf3[['Row', 'Column']].astype(np.uint32)
                    dataf3.iloc[0].apply(np.uint32)

                    dataf3.to_csv(filename + '-xyz-cis.tsv', index=False, na_rep='NaN', sep='\t')

                    pandas.DataFrame(self.dense_to_sparse(weights), columns=['Row', 'Column', 'Entry']).to_csv(
                        filename + '-spline-weights.tsv', index=False, na_rep='NaN', sep='\t')
                    # pickle.dump(tols, open('tols.p', 'w'))
                    pandas.DataFrame(self.dense_to_sparse(np.reshape(tols, (1, len(xyz_cols)))),
                                     columns=['Row', 'Column', 'Entry']).to_csv(
                        filename + '-spline-error-tolerances.tsv', index=False, na_rep='NaN', sep='\t')

                # write the data frames to CSV
                dataf1.to_csv(filename + '-xyzpts.tsv', index=False, na_rep='NaN', sep='\t')
                dataf2.to_csv(filename + '-xyzres.tsv', index=False, na_rep='NaN', sep='\t')
            else:
                # for matlab compatibility, make a residual file, even if we can't reproject
                _ = np.zeros((self.end, len(track_list_global)))
                _[:, :] = np.nan
                dataf2 = pandas.DataFrame(_, columns=sorted(track_list_global))
                dataf2.to_csv(filename + '-xyzres.csv', index=False, na_rep='NaN')
            dataf.to_csv(filename + '-xypts.tsv', index=False, na_rep='NaN', sep='\t')
            QtWidgets.QMessageBox.warning(None,f'Write successful! TSVs successfully written to {filename}.')
        return

    def save_non_sparse(self, saveas=True):
        global global_filename

        if saveas or global_filename == '':
            app = QtWidgets.QApplication.instance()
            if app is None:
                app = QtWidgets.QApplication([])
            w = SaveFilePopup("Select location and enter prefix for sparse file", global_filename.split('/')[-1], 'All files (*.*)')
            if w.filename:
                filename = w.filename
        else:
            filename = global_filename

        if filename != '' and type(filename) == str:
            global_filename = filename
            for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
                window.fill_common_dictionary()

            # get the header
            cols = sorted(common.keys())
            # stack all the columns together
            _ = common[cols[0]]
            _ = np.reshape(_, (_.shape[0], 1))
            for k in range(1, len(cols)):
                _ = np.hstack((_, np.reshape(common[cols[k]], (_.shape[0], 1))))
            # make a dataframe from the marked pixel coordinates
            dataf = pandas.DataFrame(_, columns=cols)
            pts = dataf.values

            offsets_out = list()

            for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
                offsets_out.append(window.offsets_output)

            offsets_out = np.array(offsets_out).T

            # save offsets (always non-sparse)
            datafo = pandas.DataFrame(offsets_out, columns=['camera_{0}'.format(u) for u in range(1, len(
                [u for u in pyglet.app.windows if type(u) != GhostWindow]) + 1)])
            datafo.to_csv(filename + '-offsets.csv', index=False, na_rep='NaN')

            # if we have DLT coefficients and intrinsic camera information, triangulate and write the 3D coordinates frame-by-frame
            if DLTCoefficients is not None and camera_profile is not None:
                # make a data frame for the xyz coordinates for all tracks and all frames
                xyzss = list()
                for j in range(int(pts.shape[1] / (2 * len(camera_profile)))):
                    xyzs = uv_to_xyz(pts[:, j * 2 * len(camera_profile):(j + 1) * 2 * len(camera_profile)],
                                     camera_profile, DLTCoefficients)
                    # cPickle.dump(pts[:,j*2*len(CameraProfile):(j+1)*2*len(CameraProfile)], open('points' + str(j) + '.p', 'wb'))
                    xyzss.append(xyzs)
                xyzss = np.asarray(xyzss)
                _ = xyzss[0]
                for k in range(1, len(xyzss)):
                    _ = np.hstack((_, xyzss[k]))

                xyz_cols = list()
                sTracks = sorted(track_list_global)
                for k in range(len(track_list_global)):
                    xyz_cols.append(sTracks[k] + '_x')
                    xyz_cols.append(sTracks[k] + '_y')
                    xyz_cols.append(sTracks[k] + '_z')
                dataf1 = pandas.DataFrame(_, columns=xyz_cols)

                # get reprojection errors for all 3d points and make a data frame for it
                repoErrs = get_repo_errors(_, pts, camera_profile, DLTCoefficients).T
                cols = sorted(track_list_global)
                dataf2 = pandas.DataFrame(repoErrs, columns=cols)

                if bstrap:
                    cols = list()
                    for k in range(len(track_list_global)):
                        cols.append(sTracks[k] + '_x_lower')
                        cols.append(sTracks[k] + '_y_lower')
                        cols.append(sTracks[k] + '_z_lower')
                        cols.append(sTracks[k] + '_x_upper')
                        cols.append(sTracks[k] + '_y_upper')
                        cols.append(sTracks[k] + '_z_upper')

                    CIs, weights, tols = bootstrapXYZs(pts, repoErrs, camera_profile, DLTCoefficients)
                    upper = dataf1.values + CIs
                    lower = dataf1.values - CIs

                    _ = np.zeros((upper.shape[0], upper.shape[1] * 2))
                    _[_ == 0] = np.nan
                    for k in range(upper.shape[1] // 3):
                        _[:, 2 * k * 3:2 * (k + 1) * 3] = np.concatenate(
                            (lower[:, k * 3:(k + 1) * 3], upper[:, k * 3:(k + 1) * 3]), axis=1)
                    dataf3 = pandas.DataFrame(_, columns=cols)
                    dataf3.to_csv(filename + '-xyz-cis.csv', index=False, na_rep='NaN')

                    pandas.DataFrame(weights, columns=xyz_cols).to_csv(filename + '-spline-weights.csv', index=False,
                                                                       na_rep='NaN')
                    # pickle.dump(tols, open('tols.p', 'w'))
                    pandas.DataFrame(np.reshape(tols, (1, len(xyz_cols))), columns=xyz_cols).to_csv(
                        filename + '-spline-error-tolerances.csv', index=False, na_rep='NaN')

                # write the data frames to CSV
                dataf1.to_csv(filename + '-xyzpts.csv', index=False, na_rep='NaN')
                dataf2.to_csv(filename + '-xyzres.csv', index=False, na_rep='NaN')
            else:
                # for matlab compatibility, make a residual file, even if we can't reproject
                _ = np.zeros((self.end, len(track_list_global)))
                _[:, :] = np.nan
                dataf2 = pandas.DataFrame(_, columns=sorted(track_list_global))
                dataf2.to_csv(filename + '-xyzres.csv', index=False, na_rep='NaN')
            dataf.to_csv(filename + '-xypts.csv', index=False, na_rep='NaN')
            QtWidgets.QMessageBox.warning(None, f'Write successful! CSVs successfully written to {filename}')

            settings = {
                "sync": sync,
                "displaying_all_tracks": displaying_all_tracks,
                "current_track": current_track_global,
                "auto_advance": auto_advance,
                "global_filename": global_filename,
                "rgb": rgb,
                "output_sparse": outputSparse,
                "bstrap": bstrap,
                "init_track": track_list_global[0]
            }

            ClickerProject.create(proj_path=filename,
                                  video_paths=movies_global,
                                  points=f"{filename}-xypts.csv",
                                  resolution=self.scale_factor,
                                  last_frame=self.current_point_index,
                                  offsets=f"{filename}-offsets.csv",
                                  dlt_coefficents=dlt_filename if dlt_filename else None,
                                  camera_profile=camera_filename if camera_filename else None,
                                  settings=settings)

    # pretty self explanatory
    def updateSelf(self):
        self.switch_to()
        self.update_tracks()
        self.dispatch_events()
        self.dispatch_event('on_draw')
        self.flip()

    def clearBatch(self):
        self.track_batch = pyglet.graphics.Batch()
        self.drawn_points = dict()
        self.drawn_lines = dict()
        return

    # nests potentially long operations to let the user know that the program is working hard
    def toggleBusy(self):
        global busy

        if not busy:
            busy = True
        else:
            busy = False

        self.update_all_windows()
        self.updateSelf()

    def plotTracks(self, track_indices=np.arange(len(track_list_global))):
        for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
            window.fill_common_dictionary()
        cols = sorted(common.keys())
        _ = common[cols[0]]
        _ = np.reshape(_, (_.shape[0], 1))
        for k in range(1, len(cols)):
            _ = np.hstack((_, np.reshape(common[cols[k]], (_.shape[0], 1))))
        pts = _

        fig = plt.figure()
        ax = fig.add_subplot(111, projection='3d')
        # make a data frame for the xyz coordinates for all tracks and all frames
        xyzss = list()
        for j in range(int(pts.shape[1] / (2 * len(camera_profile)))):
            xyzs = uv_to_xyz(pts[:, j * 2 * len(camera_profile):(j + 1) * 2 * len(camera_profile)], camera_profile,
                             DLTCoefficients)
            xyzss.append(xyzs)

        colors = ArgusColors().getMatplotlibColors()

        for k in range(len(track_indices)):
            xyz = xyzss[track_indices[k]]
            x = xyz[:, 0]
            y = xyz[:, 1]
            z = xyz[:, 2]
            ax.plot(x, y, z, color=colors[k % len(colors)])

        plt.show(block=False)
        # plt.close()

    def deleteTrack(self, track):
        # delete the sparse array of points
        del self.points[track]

        # delete all drawn OpenGL vertices
        for k in range(len(self.drawn_points[track])):
            if self.drawn_points[track][k] is not None:
                self.drawn_points[track][k].delete()

        for k in range(len(self.drawn_lines[track])):
            if self.drawn_lines[track][k] is not None:
                self.drawn_lines[track][k].delete()

        # delete the dictionary keys and lists themselves
        del self.drawn_points[track]
        del self.drawn_lines[track]

    def options_menu(self):
        global sync
        global auto_advance
        global track_list_global
        global current_track_global
        global current_frame
        global load_data_global
        global displaying_all_tracks
        global busy
        global bstrap
        global outputSparse
        global rgb
        global vx
        global vy

        self.toggleBusy()

        # make an options window and wait for it

        app = QtWidgets.QApplication.instance()
        if app is None:
            app = QtWidgets.QApplication([])
        w = OptionsPopupWindow(sync, auto_advance, track_list_global, current_track_global, displaying_all_tracks, bstrap, outputSparse, rgb)
        if w.exec_() == QtWidgets.QDialog.Accepted:
            auto_advance = w.auto.isChecked()
            sync = w.sync.isChecked()
            new_disp = w.disp.isChecked()
            bstrap = w.bstrap.isChecked()
            outputSparse = w.o_sparse
            rgb = w.rgb

            track_list_global = w.track_list

            for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
                window.update_tracks()

            # if the current track changed and the displaying of the rest of the tracks did not
            if current_track_global != w.tracks.currentText() and new_disp == displaying_all_tracks:
                old_track = current_track_global
                current_track_global = w.tracks.currentText()
                for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
                    window.change_track(old_track)

            # if the current track changed and the displaying of other tracks was turned on
            elif current_track_global != w.tracks.currentText() and new_disp:
                for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
                    window.draw_all_tracks()
                old_track = current_track_global
                current_track_global = w.tracks.currentText()
                displaying_all_tracks = new_disp
                for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
                    window.change_track(old_track)

            # if the current track changed and the displaying of other tracks was turned off
            elif current_track_global != w.tracks.currentText():
                old_track = current_track_global
                current_track_global = w.tracks.currentText()
                for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
                    window.change_track(old_track)
                    window.delete_all_tracks()

            # if the track did not change but we turned on displaying the rest
            elif new_disp != displaying_all_tracks and new_disp:
                for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
                    window.draw_all_tracks()

            # if the track did not change but we turned off the displaying of the rest of tracks
            elif new_disp != displaying_all_tracks and not new_disp:
                for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
                    window.delete_all_tracks()

            for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
                window.frameFinder.rgb = rgb
                im = window.frameFinder.getFrame(window.current_point_index)
                if im is not None:
                    window.img = pyglet.sprite.Sprite(ArrayInterfaceImage(im).get_texture())
                    window.img.scale = float(self.scale_factor)

            current_track_global = w.tracks.currentText()
            displaying_all_tracks = new_disp

        self.toggleBusy()
        self.update_all_windows()

    def go_to_frame(self, frame):
        global current_frame
        self.current_point_index = frame
        current_frame = self.current_point_index
        self.changed = True
        self.change_marker()

    def on_key_press(self, symbol, modifiers):
        """Manager for hotkeys
        :param symbol: Symbol passed from pyglt (?) representing the key pressed //Todo: Verify
        :param modifiers: // TODO: Document
        :return:
        """
        global sync
        global auto_advance
        global track_list_global
        global current_track_global
        global current_frame
        global load_data_global
        global displaying_all_tracks
        global busy
        global bstrap
        global outputSparse
        global rgb
        global vx
        global vy

        # brings up options dialog
        if symbol == key.O:
            self.options_menu()

        # turns on color-based contour autotracking
        elif symbol == key.A:
            self.frameFinder.destroy_kalman()
            self.frameFinder.track_image = None
            if self.autoTracking:
                self.autoTracking = False
                pyglet.clock.unschedule(up)
            else:
                if self.frameFinder.background_subtract:
                    self.frameFinder.toggleBackGroundSubtract()
                self.autoTracking = True
                pyglet.clock.schedule(up)
        elif symbol == key.V:
            if self.show_view:
                self.show_view = False
            else:
                self.show_view = True
            self.updateSelf()
        # skips one frame ahead
        elif symbol == key.F and (modifiers == 0 or modifiers == 16):
            if self.current_point_index + 1 <= self.end:
                self.changed = True
                self.current_point_index += 1
                current_frame = self.current_point_index
                self.change_marker()
                if sync:
                    self.update_all_windows()
        # skips 50 frames ahead
        elif symbol == key.F and modifiers & key.MOD_SHIFT:
            if self.current_point_index + 50 <= self.end:
                self.changed = True
                self.current_point_index += 50
                current_frame = self.current_point_index
                self.change_marker()
                if sync:
                    self.update_all_windows()
        # skips one frame behind
        elif symbol == key.B and (modifiers == 0 or modifiers == 16):
            if self.current_point_index - 1 > 0:
                self.changed = True
                self.current_point_index -= 1
                current_frame = self.current_point_index
                self.change_marker()
                if sync:
                    self.update_all_windows()
        # skips 50 frames back
        elif symbol == key.B and modifiers & key.MOD_SHIFT:
            if self.current_point_index - 50 > 0:
                self.changed = True
                self.current_point_index -= 50
                current_frame = self.current_point_index
                self.change_marker()
                if sync:
                    self.update_all_windows()
        # for capturing image
        elif symbol == key.C and modifiers & key.MOD_SHIFT:
            app = QtWidgets.QApplication.instance()
            if app is None:
                app = QtWidgets.QApplication([])
            w = SaveFilePopup("Select location to save captured image", global_filename.split('/')[-1], 'All files (*.*)')
            if w.filename:
                self.folder = w.filename
        elif symbol == key.C and modifiers & key.MOD_ALT:
            if self.folder != '':
                self.frameFinder.capture(self.folder)
            else:
                QtWidgets.QMessageBox.warning(None,
                    "Error",
                    "Must specify a directory before taking snapshots"
                )
                return
        # go to frame
        elif symbol == key.G:
            app = QtWidgets.QApplication.instance()
            if app is None:
                app = QtWidgets.QApplication([])
            w = GoToPopupWindow(self.end)
            if w.exec_() == QtWidgets.QDialog.Accepted:
                try:
                    int(w.go_to_frame)
                except:
                    QtWidgets.QMessageBox.warning(None,
                        "Error",
                        "Frame to go to must be a valid integer"
                    )
                    return

            if 1 <= int(w.go_to_frame) <= self.end:
                self.current_point_index = int(w.go_to_frame)
                current_frame = self.current_point_index
                self.changed = True
                self.change_marker()
                if sync:
                    self.update_all_windows()

            else:
                QtWidgets.QMessageBox.warning(None,
                    "Error",
                    "Frame out of bounds"
                )
        # changes track to the next one in the list
        elif symbol == key.PERIOD:
            start_time = time.time()

            old_track = current_track_global
            if track_list_global.index(current_track_global) + 1 < len(track_list_global):
                current_track_global = track_list_global[track_list_global.index(current_track_global) + 1]
            else:
                current_track_global = track_list_global[0]
            for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
                window.change_track(old_track)
            self.update_all_windows()

        # changes track to the previous one in the list
        elif symbol == key.COMMA:
            old_track = current_track_global
            if track_list_global.index(current_track_global) - 1 >= 0:
                current_track_global = track_list_global[track_list_global.index(current_track_global) - 1]
            else:
                current_track_global = track_list_global[-1]
            for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
                window.change_track(old_track)
            self.update_all_windows()
        # toggle the display of frame number in the current window
        elif symbol == key.F and modifiers & key.MOD_CTRL:
            if self.displayingFrameNumber:
                self.displayingFrameNumber = False
            else:
                self.displayingFrameNumber = True
        # reset to the original view of the entire frame
        elif symbol == key.R:
            self.left = 0
            self.right = self.frameFinder.ow
            self.bottom = 0
            self.top = self.frameFinder.oh
            self.zoom_level = 1
            self.zoomed_width = self.frameFinder.ow
            self.zoomed_height = self.frameFinder.oh
            self.frameFinder.update(self.left, self.bottom, self.right - self.left, self.top - self.bottom)
        # saving points to a CSV file
        elif symbol == key.S:
            if modifiers & key.MOD_CTRL:
                saveas = True
            else:
                saveas = False

            self.toggleBusy()
            if outputSparse:
                self.save_sparse(saveas)
            else:
                self.save_non_sparse(saveas)
            self.toggleBusy()
        elif symbol == key.X:
            self.toggleBusy()
            if sync:
                sync = False
            else:
                sync = True
            self.update_all_windows()
            self.toggleBusy()
        # skip to next marked point
        elif symbol == key.RIGHT:
            for k in range(self.current_point_index, self.points[current_track_global].shape[0]):
                if not True in (self.points[current_track_global][k].toarray() == 0):
                    self.current_point_index = k + 1
                    current_frame = self.current_point_index
                    self.change_marker()
                    if sync:
                        self.update_all_windows()
                    self.changed = True
                    break
        # skip to previously marked point
        elif symbol == key.LEFT:
            for k in range(2, self.current_point_index):
                if not True in (self.points[current_track_global][self.current_point_index - k].toarray() == 0):
                    self.current_point_index = self.current_point_index - k + 1
                    current_frame = self.current_point_index
                    self.change_marker()
                    if sync:
                        self.update_all_windows()
                    self.changed = True
                    break
        elif symbol == key.UP:
            # if not self.base:
            self.frameFinder.offset = self.frameFinder.offset + 1
            self.changed = True
            current_frame = self.current_point_index
            self.change_marker()
            if sync:
                self.update_all_windows()

        elif symbol == key.DOWN:
            # if not self.base:
            self.frameFinder.offset = self.frameFinder.offset - 1
            self.changed = True
            current_frame = self.current_point_index
            self.change_marker()
            if sync:
                self.update_all_windows()

        elif symbol == key.I:
            if vx - 1 >= 5:
                vx -= 1
        elif symbol == key.Y:
            if vx + 1 <= 30:
                vx += 1
        elif symbol == key.U:
            if vy - 1 >= 5:
                vy -= 1
        elif symbol == key._7:
            if vy + 1 <= 30:
                vy += 1

        # clearing all tracks from the current window
        elif symbol == key.C and (modifiers == 0 or modifiers == 16):
            app = QtWidgets.QApplication.instance()
            if app is None:
                app = QtWidgets.QApplication([])
            w = YesNoPopup(f"Clear all tracks for camera {actual_camera_number}. Are you sure?")
            if w.exec_() == QtWidgets.QDialog.Accepted:
                if w.reply == 'Yes':
                    self.points = dict()
                    self.clearBatch()
                    self.update_tracks()
        elif symbol == key.D and modifiers & key.MOD_SHIFT:
            if len(track_list_global) > 1:
                app = QtWidgets.QApplication.instance()
                if app is None:
                    app = QtWidgets.QApplication([])
                w = YesNoPopup(f"Delete track {current_track_global}. Are you sure?")
                if w.exec_() == QtWidgets.QDialog.Accepted:
                    if w.reply == 'Yes':
                        old_track = current_track_global
                        track_list_global.remove(current_track_global)
                        if len(track_list_global) != 0:
                            current_track_global = track_list_global[0]
                        for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
                            window.change_track(old_track)
                            window.deleteTrack(old_track)
                        self.update_all_windows()
            else:
                QtWidgets.QMessageBox.warning(None,
                    "Error",
                    "Cannot delete track, must have at least one track to work with. Please add add a new track before deleting this one."
                )
            # self.trackingColors = list()
        # loading points from a CSV file
        elif symbol == key.L:
            self.toggleBusy()
            app = QtWidgets.QApplication.instance()
            if app is None:
                app = QtWidgets.QApplication([])
            w = OpenFilePopup("Select _xypts.csv file", 'CSV (*.csv)')
            if w.filename:
                if type(filename) == str:
                    if filename != '' and filename.split('.')[-1] == 'csv':
                        load_csv(filename)

                    elif filename != '' and filename.split('.')[-1] == 'tsv':
                        outputSparse = True

                        load_tsv(filename)

            if load_data_global is not None:
                offsetMatches = list()
                for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
                    window.points = dict()
                    window.update_tracks()
                    offsetMatches.append(window.load_points())
                    window.updateSelf()
                if False in offsetMatches:
                    QtWidgets.QMessageBox.warning(None,
                        "Warning",
                        "Offsets may be wrong. There are more frames in the loaded CSV than there are in the first camera"
                    )

                load_data_global = None
            self.toggleBusy()
        # delete the point in the current frame and track
        elif symbol == key.D and (modifiers == 0 or modifiers == 16):
            positions = copy.copy(self.points[current_track_global])
            positions[self.current_point_index - 1] = np.asarray([0., 0.])
            positions.eliminate_zeros()
            self.points[current_track_global] = positions
            self.delete_point()
        # plot 3D tracks if we have dlt coefficients and camera profile
        elif symbol == key.P:
            self.toggleBusy()
            # if we have DLT coefficients and intrinsic camera information,
            # triangulate and write the 3D coordinates frame-by-frame
            if DLTCoefficients is not None and camera_profile is not None:
                self.plotTracks(track_indices=np.arange(len(track_list_global)))
            else:
                QtWidgets.QMessageBox.warning(None,
                    "Error",
                    "Must have DLT coefficients and a camera profile to obtain 3D coordinates"
                )
            self.toggleBusy()
        elif symbol == key.P and modifiers & key.MOD_CTRL:
            self.toggleBusy()
            if DLTCoefficients is not None and camera_profile is not None:
                self.plotTracks(track_indices=[track_list_global.index(current_track_global)])
            else:
                QtWidgets.QMessageBox.warning(None,
                    "Error",
                    "Must have DLT coefficients and a camera profile to obtain 3D coordinates"
                )
            self.toggleBusy()

    def on_mouse_press(self, x, y, buttons, modifiers):
        global sync
        global auto_advance
        global track_list_global
        global current_track_global
        global current_frame

        if buttons & mouse.LEFT:
            if current_track_global != '' and (modifiers == 16 or modifiers == 0):
                self.draw_new_point(float(x) / self.width * self.zoomed_width + self.left,
                                    float(y) / self.height * self.zoomed_height + self.bottom)
                if auto_advance:
                    im = self.frameFinder.getFrame(self.current_point_index + 1)
                    if im is not None and self.current_point_index + 1 <= self.end:
                        self.changed = True
                        self.current_point_index += 1
                        self.change_marker()
                        current_frame = self.current_point_index
                        if sync:
                            self.update_all_windows()
            elif modifiers & key.MOD_CTRL:
                self.trackingColors.append(self.frameFinder.getColor(np.asarray(
                    [float(x) / self.width * self.zoomed_width + self.left,
                     float(y) / self.height * self.zoomed_height + self.bottom])))

        elif buttons & mouse.RIGHT:
            positions = copy.copy(self.points[current_track_global])
            positions[self.current_point_index - 1] = np.asarray([0., 0.])
            positions.eliminate_zeros()
            self.points[current_track_global] = positions
            self.delete_point()



    def on_mouse_motion(self, x, y, dx, dy):
        self.x = float(x) / self.width * self.zoomed_width + self.left
        self.y = self.frameFinder.oh - (float(y) / self.height * self.zoomed_height + self.bottom)


# function scheduled everytime autotracking is turned on
# to create a loop. it is unscheduled when autotracking is turned off
def up(dt):
    for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
        window.tick()
    # time.sleep(0.1)


# checks if there are other windows besides the Ghost Window
def check_to_close(dt):
    windows = [u for u in pyglet.app.windows]
    if len(windows) == 1:
        if type(windows[0]) == GhostWindow:
            windows[0].close()


# ghost window by Ty
class GhostWindow(pyglet.window.Window):
    def __init__(self):
        super(GhostWindow, self).__init__(width=10, height=10, visible=False, resizable=False)


def parse_csv(csv: str) -> lil_matrix:
    """Parses a csv file for a point matrix as formatted by argus
    :param csv: A path to a .csv file
    :return: a scipy lil_matrix with points like:
        [
            [cam1_x_track_1, cam1_y_track_1, cam2_x_track_1, cam2_y_track_1, ...., camN_x_track_1, camN_x_track_2]
            .
            .
            .
            [...]
        ]
        where each row represents a frame number corresponding to the original video
    """
    if csv.split('.')[-1] == 'csv':
        dataf = pandas.read_csv(csv, index_col=False)
        return dataf.values
    # else check if we have sparse data representation
    elif csv.split('.')[-1] == 'tsv':
        fo = open(csv)
        # expect a header
        line = fo.readline()
        # next line has shape information for the sparse matrix
        line = fo.readline()
        shape = list(map(int, line.split('\t')))
        # ret = lil_matrix((shape[0], shape[1]))
        ret = lil_matrix((shape[0], shape[1]))
        ret[:, :] = np.nan
        line = fo.readline()
        while line != '':
            val = list(map(float, line.split('\t')))
            ret[int(val[0]) - 1, int(val[1]) - 1] = val[2]
            line = fo.readline()
        return ret


def check_if_file(path):
    if path is None: return
    if not os.path.isfile(path):
        QtWidgets.QMessageBox.warning(None,
            "Error",
            f"Unable to locate {path}"
        )
        return False

    else: return True


def load_settings(settings):
    global sync
    global displaying_all_tracks
    global current_track_global
    global auto_advance
    global global_filename
    global rgb
    global outputSparse
    global bstrap

    sync = settings["sync"]
    displaying_all_tracks = settings["displaying_all_tracks"]
    current_track_global = settings["current_track"]
    auto_advance = settings["auto_advance"]
    global_filename = settings["global_filename"]
    rgb = settings["rgb"]
    outputSparse = settings["output_sparse"]
    bstrap = settings["bstrap"]


def load_from_config(path):
    global movies_global
    global DLTCoefficients
    global dlt_filename

    with open(path) as f:
        project = yaml.load(f, Loader=yaml.FullLoader)

    project_videos = project[0]

    project_points = project[1]
    if not check_if_file(project_points["points"]): return

    project_resultion = project[2]
    project_last_frame = project[3]

    project_offsets = project[4]
    if not check_if_file(project_offsets["offsets"]): return
    loaded_offsets = project_offsets["offsets"]

    frame_number = project_last_frame["last_frame"]
    loaded_res = project_resultion["resolution"]

    loaded_movies = project_videos["videos"]
    movies_global = loaded_movies

    loaded_offsets = parse_csv(loaded_offsets)
    useable_offsets = []

    dlt_coeff = project[5]
    dlt_path = dlt_coeff["dlt_coefficents"]
    if check_if_file(dlt_path):
        DLTCoefficients = np.loadtxt(dlt_path, delimiter=',')
        DLTCoefficients = DLTCoefficients.T
        dlt_filename = dlt_path

    camera_profile = project[6]
    camera_profile_path = camera_profile["camera_profile"]
    if check_if_file(camera_profile_path):
        load_camera(camera_profile_path)

    for camera_index in range(0, len(loaded_movies)):
        offset = loaded_offsets[frame_number - 2][camera_index]
        if np.isnan(offset):
            offset = 0
        useable_offsets.append(offset)

    loaded_end = int(cv2.VideoCapture(loaded_movies[0]).get(cv2.CAP_PROP_FRAME_COUNT))

    windows = []
    for index, movie in enumerate(loaded_movies):
        if not check_if_file(movie): return
        if index != len(loaded_movies) - 1:
            mov = ClickerWindow(movie, offsets=useable_offsets, actual_camera_number=index + 1, end=loaded_end,
                              factor=loaded_res)
            mov.go_to_frame(frame_number)

            windows.append(mov)

        else:
            mov = ClickerWindow(movie, offsets=useable_offsets, actual_camera_number=index + 1, end=loaded_end,
                                         factor=loaded_res,
                                         last=True)
            mov.go_to_frame(frame_number)
            windows.append(mov)

    load_csv(project_points["points"])

    settings = project[7]["settings"]
    load_settings(settings)

    if sys.platform == 'win32':
        pyglet.clock.schedule_once(check_to_close, .5)

    def update_after(_):
        indexable_windows = [u for u in windows if type(u) != GhostWindow]
        if load_data_global is not None:
            offsetMatches = list()
            for window in indexable_windows:
                window.points = dict()
                window.update_tracks()
                offsetMatches.append(window.load_points())
                window.updateSelf()

        indexable_windows[0].change_track(settings["init_track"])
        indexable_windows[0].update_all_windows()

        for window in indexable_windows:
            window.switch_to()
            window.update_tracks()
            window.dispatch_events()
            window.dispatch_event('on_draw')
            window.flip()

            window.frameFinder.rgb = rgb
            im = window.frameFinder.getFrame(window.current_point_index)
            if im is not None:
                window.img = pyglet.sprite.Sprite(ArrayInterfaceImage(im).get_texture())
                window.img.scale = float(window.scale_factor)

    pyglet.clock.schedule_once(update_after, .05)
    pyglet.app.run()


if __name__ == '__main__':
    movies_global = None
    if sys.argv[1].startswith("configload@"):
        load_from_config(sys.argv[1].split("@")[1])

    else:
        end = int(sys.argv[2])
        movies_global = sys.argv[1].split('@')

        movies = movies_global
        offsets = list(map(int, sys.argv[3].split('@')))
        factor = int(sys.argv[4])

        windows = []
        for index, movie in enumerate(movies):
            if index != len(movies) - 1:
                curWindow = ClickerWindow(movie, offsets=offsets, actual_camera_number=index + 1, end=end, factor=factor)
                windows.append(curWindow)
                if offsets[index] != 0 and offsets[index] < 0:
                    curWindow.go_to_frame(1 + np.abs(offsets[index]))
            else:
                curWindow = ClickerWindow(movie, offsets=offsets, actual_camera_number=index + 1, end=end, factor=factor,
                                          last=True)

                windows.append(curWindow)
                if offsets[index] != 0 and offsets[index] < 0:       
                    curWindow.go_to_frame(1 + np.abs(offsets[index]))

        if sys.platform == 'win32':
            pyglet.clock.schedule_once(check_to_close, .5)

        pyglet.app.run()
